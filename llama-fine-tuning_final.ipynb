{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9934971,"sourceType":"datasetVersion","datasetId":6104419}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch # torch\n!pip install peft # necessary for finetuning of the large model via LoRA approach\n!pip install bitsandbytes # necessary for quantiziation\n!pip install evaluate # extension of the transformers library\n!pip install datasets # extension of the transformers library\n!pip install accelerate","metadata":{"_uuid":"b27298b3-c437-48ed-bfa6-fb925aa71541","_cell_guid":"6c0d7ab3-bd30-425c-8ae7-5d02608d3b86","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-19T09:56:06.837166Z","iopub.execute_input":"2024-11-19T09:56:06.837787Z","iopub.status.idle":"2024-11-19T09:57:03.046891Z","shell.execute_reply.started":"2024-11-19T09:56:06.837750Z","shell.execute_reply":"2024-11-19T09:57:03.045791Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nCollecting peft\n  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.34.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.13.2\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.44.1\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.25.1)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom datasets import Dataset, load_dataset\nfrom peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\nfrom transformers import (\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    EarlyStoppingCallback,\n    DataCollatorWithPadding)\n\nimport bitsandbytes as bnb\n\nimport evaluate\nimport numpy as np\n\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:57:03.049229Z","iopub.execute_input":"2024-11-19T09:57:03.050224Z","iopub.status.idle":"2024-11-19T09:57:23.086805Z","shell.execute_reply.started":"2024-11-19T09:57:03.050182Z","shell.execute_reply":"2024-11-19T09:57:23.085883Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from huggingface_hub import login\nlogin('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')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:57:23.088125Z","iopub.execute_input":"2024-11-19T09:57:23.088676Z","iopub.status.idle":"2024-11-19T09:57:23.303687Z","shell.execute_reply.started":"2024-11-19T09:57:23.088647Z","shell.execute_reply":"2024-11-19T09:57:23.302727Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"dataset = load_dataset(\"glue\", \"sst2\")\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:57:23.306052Z","iopub.execute_input":"2024-11-19T09:57:23.306422Z","iopub.status.idle":"2024-11-19T09:57:34.498104Z","shell.execute_reply.started":"2024-11-19T09:57:23.306383Z","shell.execute_reply":"2024-11-19T09:57:34.497129Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/35.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9567e9d442a74cac9aa3f6c49cfbf33c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/3.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db94bc66b1f14f3cab5c4525a0e69998"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/72.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a347c046a5fa499a88fb2cd84b8e7fe4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/148k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4452514372c24fe1b3fef0252616d526"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f058ca433df40af928a1f440abb1a81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40223763e2854f89ae6f7d00f6293b12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd023045b63f43d09d1bd2d6db1b0b39"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['sentence', 'label', 'idx'],\n        num_rows: 67349\n    })\n    validation: Dataset({\n        features: ['sentence', 'label', 'idx'],\n        num_rows: 872\n    })\n    test: Dataset({\n        features: ['sentence', 'label', 'idx'],\n        num_rows: 1821\n    })\n})"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Step 1: Split the original training data (80% for training, 20% for testing)\ntrain_test_split = dataset[\"train\"].train_test_split(test_size=0.2, seed=1)\n\n# Step 2: Now, take 10% of the new 80% training data as the validation set\ntrain_val_split = train_test_split[\"train\"].train_test_split(test_size=0.1, seed=1)\n\n# Step 3: Update the dataset with the new splits\ndataset[\"train\"] = train_val_split[\"train\"]  # 70% of original data\ndataset[\"validation\"] = train_val_split[\"test\"]  # 10% of original data\ndataset[\"test\"] = train_test_split[\"test\"]  # 20% of original data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:57:48.441619Z","iopub.execute_input":"2024-11-19T09:57:48.442010Z","iopub.status.idle":"2024-11-19T09:57:48.481127Z","shell.execute_reply.started":"2024-11-19T09:57:48.441980Z","shell.execute_reply":"2024-11-19T09:57:48.480405Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:57:49.630543Z","iopub.execute_input":"2024-11-19T09:57:49.630924Z","iopub.status.idle":"2024-11-19T09:57:49.637072Z","shell.execute_reply.started":"2024-11-19T09:57:49.630892Z","shell.execute_reply":"2024-11-19T09:57:49.636214Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n        num_rows: 34912\n    })\n    validation: Dataset({\n        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n        num_rows: 3880\n    })\n    test: Dataset({\n        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n        num_rows: 9699\n    })\n})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\nmodel_id  = \"meta-llama/Llama-3.2-1B-Instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:58:00.545383Z","iopub.execute_input":"2024-11-19T09:58:00.546060Z","iopub.status.idle":"2024-11-19T09:58:01.292652Z","shell.execute_reply.started":"2024-11-19T09:58:00.546029Z","shell.execute_reply":"2024-11-19T09:58:01.291947Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples[\"sentence\"], truncation=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:58:01.294866Z","iopub.execute_input":"2024-11-19T09:58:01.295233Z","iopub.status.idle":"2024-11-19T09:58:01.299368Z","shell.execute_reply.started":"2024-11-19T09:58:01.295193Z","shell.execute_reply":"2024-11-19T09:58:01.298579Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"dataset = dataset.map(preprocess_function, batched=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:58:01.864666Z","iopub.execute_input":"2024-11-19T09:58:01.865045Z","iopub.status.idle":"2024-11-19T09:58:05.834212Z","shell.execute_reply.started":"2024-11-19T09:58:01.865015Z","shell.execute_reply":"2024-11-19T09:58:05.833097Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/34912 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07ad43b1effe47f5b676f64c327257ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3880 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d21a22adc1764992bd9a47d886665b87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9699 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ed98b10ac414ded8fe3ee193e9475eb"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:58:05.916254Z","iopub.execute_input":"2024-11-19T09:58:05.916620Z","iopub.status.idle":"2024-11-19T09:58:05.921402Z","shell.execute_reply.started":"2024-11-19T09:58:05.916569Z","shell.execute_reply":"2024-11-19T09:58:05.920529Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"\naccuracy = evaluate.load(\"accuracy\")\nf1 = evaluate.load(\"f1\", average=\"macro\")\nprecision = evaluate.load(\"precision\", average=\"macro\")\nrecall = evaluate.load(\"recall\", average=\"macro\")\n\n# Combine the individual metrics into a single metric\nmetric = evaluate.combine([accuracy, f1, precision, recall])\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)  # Convert probabilities to predicted labels\n    return metric.compute(predictions=predictions, references=labels)\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:58:06.339217Z","iopub.execute_input":"2024-11-19T09:58:06.339618Z","iopub.status.idle":"2024-11-19T09:58:12.642356Z","shell.execute_reply.started":"2024-11-19T09:58:06.339588Z","shell.execute_reply":"2024-11-19T09:58:12.641734Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8242aa7326c7431a87bbbe408301902e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"273b3eeb41294c1bb0807844028ac19f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8bd9102ca7a43048c4154e6bd893ed4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.36k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1c8267c1b70461a9c1740d23d0a6b91"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,  # Enables 4-bit quantization\n    bnb_4bit_use_double_quant=True,  # Use double quantization for potentially higher accuracy (optional)\n    bnb_4bit_quant_type=\"nf4\",  # Quantization type (specifics depend on hardware and library)\n    bnb_4bit_compute_dtype=torch.bfloat16  # Compute dtype for improved efficiency (optional)\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:58:12.643802Z","iopub.execute_input":"2024-11-19T09:58:12.644064Z","iopub.status.idle":"2024-11-19T09:58:12.649191Z","shell.execute_reply.started":"2024-11-19T09:58:12.644039Z","shell.execute_reply":"2024-11-19T09:58:12.648490Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    model_id,\n    num_labels=2,\n    quantization_config=bnb_config,  # configuration for quantization\n    device_map={\"\": 0}  # Optional dictionary specifying device mapping (single GPU with index 0 here)\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:58:55.188306Z","iopub.execute_input":"2024-11-19T09:58:55.189164Z","iopub.status.idle":"2024-11-19T09:59:32.264373Z","shell.execute_reply.started":"2024-11-19T09:58:55.189131Z","shell.execute_reply":"2024-11-19T09:59:32.263453Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:  42%|####2     | 1.05G/2.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d53e01320814125afbd08caabcb2b76"}},"metadata":{}},{"name":"stderr","text":"Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B-Instruct and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"model.gradient_checkpointing_enable()\nmodel = prepare_model_for_kbit_training(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:59:32.291095Z","iopub.execute_input":"2024-11-19T09:59:32.291327Z","iopub.status.idle":"2024-11-19T09:59:32.310385Z","shell.execute_reply.started":"2024-11-19T09:59:32.291302Z","shell.execute_reply":"2024-11-19T09:59:32.309020Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"\ndef find_linear_names(model):\n    \"\"\"\n    This function identifies all linear layer names within a model that use 4-bit quantization.\n    Args:\n        model (torch.nn.Module): The PyTorch model to inspect.\n    Returns:\n        list: A list containing the names of all identified linear layers with 4-bit quantization.\n    \"\"\"\n    cls = bnb.nn.Linear4bit\n\n    # Set to store identified layer names\n    lora_module_names = set()\n\n    # Iterate through named modules in the model\n    for name, module in model.named_modules():\n        # Check if the current module is an instance of the 4-bit linear layer class\n        if isinstance(module, cls):\n            names = name.split('.')\n            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n\n        # Special case: remove 'lm_head' if present\n        if 'lm_head' in lora_module_names:\n            lora_module_names.remove('lm_head')\n    return list(lora_module_names)\n\n# Example usage:\nmodules = find_linear_names(model)\nprint(modules)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:59:32.311745Z","iopub.execute_input":"2024-11-19T09:59:32.311989Z","iopub.status.idle":"2024-11-19T09:59:32.480035Z","shell.execute_reply.started":"2024-11-19T09:59:32.311965Z","shell.execute_reply":"2024-11-19T09:59:32.478989Z"}},"outputs":[{"name":"stdout","text":"['up_proj', 'k_proj', 'q_proj', 'down_proj', 'o_proj', 'v_proj', 'gate_proj']\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=8,  # Reduction factor (lower r means more parameters in the adapter)\n    lora_alpha=8,  # Dimensionality of the adapter projection\n    target_modules=modules,  # List of modules to apply the LoRA adapter\n    lora_dropout=0.05,  # Dropout rate for the adapter\n    bias=\"none\",  # Bias configuration for the adapter\n    task_type=\"SEQ_CLS\"  # Task type (sequence classification in this case)\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:59:32.481080Z","iopub.execute_input":"2024-11-19T09:59:32.481336Z","iopub.status.idle":"2024-11-19T09:59:32.689698Z","shell.execute_reply.started":"2024-11-19T09:59:32.481312Z","shell.execute_reply":"2024-11-19T09:59:32.688692Z"}},"outputs":[{"name":"stdout","text":"trainable params: 5,640,192 || all params: 1,241,458,688 || trainable%: 0.4543\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"\ntraining_args = TrainingArguments(\n    output_dir=\"epoch_weights\",  # Output directory for checkpoints\n    learning_rate=2e-5,  # Learning rate for the optimizer\n    per_device_train_batch_size=1,  # Batch size per device\n    per_device_eval_batch_size=1,  # Batch size per device for evaluation\n    num_train_epochs=2,  # Number of training epochs\n    weight_decay=0.01,  # Weight decay for regularization\n    evaluation_strategy='epoch',  # Evaluate after each epoch\n    save_strategy=\"epoch\",  # Save model checkpoints after each epoch\n    load_best_model_at_end=True,  # Load the best model based on the chosen metric\n    push_to_hub=False,  # Disable pushing the model to the Hugging Face Hub\n    report_to=\"none\",  # Disable logging to Weight&Bias\n    metric_for_best_model='eval_loss')  # Metric for selecting the best model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:59:55.214415Z","iopub.execute_input":"2024-11-19T09:59:55.215286Z","iopub.status.idle":"2024-11-19T09:59:55.246650Z","shell.execute_reply.started":"2024-11-19T09:59:55.215251Z","shell.execute_reply":"2024-11-19T09:59:55.245802Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"\ntokenizer.pad_token = tokenizer.eos_token\n\ntrainer = Trainer(\n    model=model,  # The LoRA-adapted model\n    args=training_args,  # Training arguments\n    train_dataset=dataset['train'],  # Training dataset\n    eval_dataset=dataset['validation'],  # Evaluation dataset\n    tokenizer=tokenizer,  # Tokenizer for processing text\n    data_collator=data_collator,  # Data collator for preparing batches\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:59:57.543517Z","iopub.execute_input":"2024-11-19T09:59:57.543878Z","iopub.status.idle":"2024-11-19T14:47:52.314908Z","shell.execute_reply.started":"2024-11-19T09:59:57.543846Z","shell.execute_reply":"2024-11-19T14:47:52.313951Z"}},"outputs":[{"name":"stderr","text":"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='69824' max='69824' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [69824/69824 4:47:53, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.384000</td>\n      <td>0.338281</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.191400</td>\n      <td>0.329133</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=69824, training_loss=0.31406385842864387, metrics={'train_runtime': 17274.1987, 'train_samples_per_second': 4.042, 'train_steps_per_second': 4.042, 'total_flos': 5391952725196800.0, 'train_loss': 0.31406385842864387, 'epoch': 2.0})"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"model.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T14:58:48.708928Z","iopub.execute_input":"2024-11-19T14:58:48.709212Z","iopub.status.idle":"2024-11-19T14:58:48.717925Z","shell.execute_reply.started":"2024-11-19T14:58:48.709184Z","shell.execute_reply":"2024-11-19T14:58:48.716991Z"}},"outputs":[{"name":"stdout","text":"trainable params: 5,640,192 || all params: 1,241,458,688 || trainable%: 0.4543\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Example: After fine-tuning\nmodel_name = \"llama_3_2_fine_tuning\"  # Replace with your fine-tuned model's name\n\n# Save the model\nmodel.save_pretrained(\"/kaggle/working/fine_tuning\")  # Path where the model will be saved\n\n# Save the tokenizer\ntokenizer.save_pretrained(\"/kaggle/working/fine_tuning\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T14:59:04.790474Z","iopub.execute_input":"2024-11-19T14:59:04.791395Z","iopub.status.idle":"2024-11-19T14:59:05.560549Z","shell.execute_reply.started":"2024-11-19T14:59:04.791361Z","shell.execute_reply":"2024-11-19T14:59:05.559640Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/fine_tuning/tokenizer_config.json',\n '/kaggle/working/fine_tuning/special_tokens_map.json',\n '/kaggle/working/fine_tuning/tokenizer.json')"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"from huggingface_hub import HfApi\n\n# Push the model to Hugging Face Model Hub\nmodel.push_to_hub(\"llama_fine_tuning\")  # Replace with your model's name on Hugging Face Hub\ntokenizer.push_to_hub(\"tokenizer\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T14:59:09.725431Z","iopub.execute_input":"2024-11-19T14:59:09.726141Z","iopub.status.idle":"2024-11-19T14:59:23.292417Z","shell.execute_reply.started":"2024-11-19T14:59:09.726105Z","shell.execute_reply":"2024-11-19T14:59:23.291584Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/22.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f13e6c5d7ef4d55bc795c05c6595dd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee218e2a71e4449495a06eb2817dbfe7"}},"metadata":{}},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/munikumar4689/tokenizer/commit/0420c8e5c574eacf094f2559460b23f76a0e1b90', commit_message='Upload tokenizer', commit_description='', oid='0420c8e5c574eacf094f2559460b23f76a0e1b90', pr_url=None, repo_url=RepoUrl('https://huggingface.co/munikumar4689/tokenizer', endpoint='https://huggingface.co', repo_type='model', repo_id='munikumar4689/tokenizer'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"\npreds = trainer.predict(dataset['test'])\nimport numpy as np\nfrom sklearn.metrics import classification_report,confusion_matrix\n\npreds_flat = [np.argmax(x) for x in preds[0]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T14:47:52.316641Z","iopub.execute_input":"2024-11-19T14:47:52.316948Z","iopub.status.idle":"2024-11-19T14:58:48.680897Z","shell.execute_reply.started":"2024-11-19T14:47:52.316921Z","shell.execute_reply":"2024-11-19T14:58:48.680177Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"\nprint(classification_report(dataset['test']['label'], preds_flat))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T14:58:48.681951Z","iopub.execute_input":"2024-11-19T14:58:48.682203Z","iopub.status.idle":"2024-11-19T14:58:48.706914Z","shell.execute_reply.started":"2024-11-19T14:58:48.682179Z","shell.execute_reply":"2024-11-19T14:58:48.706015Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.94      0.95      0.94      4250\n           1       0.96      0.95      0.96      5449\n\n    accuracy                           0.95      9699\n   macro avg       0.95      0.95      0.95      9699\nweighted avg       0.95      0.95      0.95      9699\n\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# import matplotlib as plt\n# import seaborn as sns\n# from matplotlib import pyplot as plt\n\n\n# # plot the heat map\n# sns.heatmap(\n#     confusion_matrix(test_dataset['label'], preds_flat),\n#     annot=True,\n#     xticklabels=['World','Sports','Business','Sci/tech'],\n#     yticklabels=['World','Sports','Business','Sci/tech'],\n#     cmap=plt.cm.magma_r\n# )\n# plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}