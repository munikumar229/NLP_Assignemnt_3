{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-11-17T18:07:28.142808Z","iopub.status.busy":"2024-11-17T18:07:28.142347Z","iopub.status.idle":"2024-11-17T18:07:28.639664Z","shell.execute_reply":"2024-11-17T18:07:28.638770Z","shell.execute_reply.started":"2024-11-17T18:07:28.142775Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: fineGrained).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["from huggingface_hub import login\n","login('hf_token')  # This will prompt you to enter your Hugging Face token\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-11-17T18:07:28.641446Z","iopub.status.busy":"2024-11-17T18:07:28.641194Z","iopub.status.idle":"2024-11-17T18:08:59.871200Z","shell.execute_reply":"2024-11-17T18:08:59.870181Z","shell.execute_reply.started":"2024-11-17T18:07:28.641420Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/site-packages/torch_xla/__init__.py:202: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n","  warnings.warn(\n"]}],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","\n","model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\",\n","                                            torch_dtype = torch.bfloat16)\n","tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\",padding_side='left')\n","tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-11-17T18:08:59.873335Z","iopub.status.busy":"2024-11-17T18:08:59.872892Z","iopub.status.idle":"2024-11-17T18:09:01.651933Z","shell.execute_reply":"2024-11-17T18:09:01.651104Z","shell.execute_reply.started":"2024-11-17T18:08:59.873304Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>phrase</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>!</td>\n","      <td>Neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>! '</td>\n","      <td>Neutral</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>! ''</td>\n","      <td>Neutral</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>! Alas</td>\n","      <td>Neutral</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>! Brilliant</td>\n","      <td>Very_Positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        phrase         labels\n","0            !        Neutral\n","1          ! '        Neutral\n","2         ! ''        Neutral\n","3       ! Alas        Neutral\n","4  ! Brilliant  Very_Positive"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","classes = [\"Very_Negative\", \"Negative\", \"Neutral\", \"Positive\", \"Very_Positive\"]\n","df = pd.read_csv('/kaggle/input/sst2-data/sst2/preprocessed_data.csv')\n","df = df[df['labels'].isin(classes)]\n","df.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-11-17T18:09:01.653411Z","iopub.status.busy":"2024-11-17T18:09:01.653115Z","iopub.status.idle":"2024-11-17T18:09:01.700717Z","shell.execute_reply":"2024-11-17T18:09:01.699717Z","shell.execute_reply.started":"2024-11-17T18:09:01.653381Z"},"trusted":true},"outputs":[],"source":["df = df.sample(frac =1,random_state = 1).reset_index(drop=True).reset_index()\n","train_size = 0.8\n","train_len = int(train_size*len(df))"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-11-17T18:09:01.703073Z","iopub.status.busy":"2024-11-17T18:09:01.702784Z","iopub.status.idle":"2024-11-17T18:09:01.707700Z","shell.execute_reply":"2024-11-17T18:09:01.706863Z","shell.execute_reply.started":"2024-11-17T18:09:01.703045Z"},"trusted":true},"outputs":[],"source":["df_train = df[:train_len]\n","df_test = df[train_len:]"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-11-17T18:09:01.708940Z","iopub.status.busy":"2024-11-17T18:09:01.708677Z","iopub.status.idle":"2024-11-17T18:09:01.728419Z","shell.execute_reply":"2024-11-17T18:09:01.727276Z","shell.execute_reply.started":"2024-11-17T18:09:01.708913Z"},"trusted":true},"outputs":[{"data":{"text/plain":["((191385, 3), (47847, 3))"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df_train.shape,df_test.shape"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-11-17T18:09:01.729861Z","iopub.status.busy":"2024-11-17T18:09:01.729566Z","iopub.status.idle":"2024-11-17T18:09:01.767451Z","shell.execute_reply":"2024-11-17T18:09:01.766661Z","shell.execute_reply.started":"2024-11-17T18:09:01.729832Z"},"trusted":true},"outputs":[],"source":["classes = [\"Very_Negative\", \"Negative\", \"Neutral\", \"Positive\", \"Very_Positive\"]\n","\n","# Instead of embedding \\n directly inside the f-string, we'll handle it separately\n","classes_with_labels = \"\\n or \".join([f\"Category: {x}\" for x in classes])\n","\n","system_prompt = {\n","    \"role\": \"system\",\n","    \"content\": f\"\"\"You are an expert in sentiment analysis who classifies the sentiment of a phrase. You have to choose only one class from the following classes:\n","{classes_with_labels}.\n","Ensure your output is from the above list only.\"\"\"\n","}\n","\n","post_message = {\n","    \"role\": \"assistant\",\n","    \"content\": \"Category:\"\n","}\n","\n","user_messages = [\n","    {\n","        \"role\": \"user\",\n","        \"content\": f\"Phrase: {row['phrase']}\"\n","    }\n","    for _, row in df_test.iloc[:500].iterrows()  # Correct iteration over DataFrame rows\n","]\n","\n","prompts = [\n","    [system_prompt, user_msg, post_message]\n","    for user_msg in user_messages\n","]\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-11-17T18:09:01.768842Z","iopub.status.busy":"2024-11-17T18:09:01.768536Z","iopub.status.idle":"2024-11-17T18:09:01.774111Z","shell.execute_reply":"2024-11-17T18:09:01.773385Z","shell.execute_reply.started":"2024-11-17T18:09:01.768812Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[{'role': 'system',\n","  'content': 'You are an expert in sentiment analysis who classifies the sentiment of a phrase. You have to choose only one class from the following classes:\\nCategory: Very_Negative\\n or Category: Negative\\n or Category: Neutral\\n or Category: Positive\\n or Category: Very_Positive.\\nEnsure your output is from the above list only.'},\n"," {'role': 'user', 'content': 'Phrase: require the full emotional involvement'},\n"," {'role': 'assistant', 'content': 'Category:'}]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["prompts[0]"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-11-17T18:09:01.775248Z","iopub.status.busy":"2024-11-17T18:09:01.774996Z","iopub.status.idle":"2024-11-17T18:16:05.305087Z","shell.execute_reply":"2024-11-17T18:16:05.303889Z","shell.execute_reply.started":"2024-11-17T18:09:01.775222Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"]}],"source":["tokenized = tokenizer.apply_chat_template(\n","    prompts,\n","    continue_final_message = True,\n","    padding=True,\n","    return_tensors = 'pt'\n",")\n","\n","out = model.generate(tokenized,max_new_tokens=25)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-11-17T18:17:40.454491Z","iopub.status.busy":"2024-11-17T18:17:40.453851Z","iopub.status.idle":"2024-11-17T18:17:40.507455Z","shell.execute_reply":"2024-11-17T18:17:40.506623Z","shell.execute_reply.started":"2024-11-17T18:17:40.454462Z"},"trusted":true},"outputs":[],"source":["decode = tokenizer.batch_decode(out)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-11-17T18:16:05.363025Z","iopub.status.busy":"2024-11-17T18:16:05.362741Z","iopub.status.idle":"2024-11-17T18:16:05.367863Z","shell.execute_reply":"2024-11-17T18:16:05.367104Z","shell.execute_reply.started":"2024-11-17T18:16:05.362997Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 17 Nov 2024\\n\\nYou are an expert in sentiment analysis who classifies the sentiment of a phrase. You have to choose only one class from the following classes:\\nCategory: Very_Negative\\n or Category: Negative\\n or Category: Neutral\\n or Category: Positive\\n or Category: Very_Positive.\\nEnsure your output is from the above list only.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nPhrase: require the full emotional involvement<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nCategory: Positive\\n or Category: Neutral\\n or Category: Neutral\\n or Category: Positive<|eot_id|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|>'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["decode[0]"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-11-17T18:16:05.369115Z","iopub.status.busy":"2024-11-17T18:16:05.368839Z","iopub.status.idle":"2024-11-17T18:16:05.378693Z","shell.execute_reply":"2024-11-17T18:16:05.378007Z","shell.execute_reply.started":"2024-11-17T18:16:05.369067Z"},"trusted":true},"outputs":[],"source":["predicted_labels = [d.split('<|start_header_id|>assistant<|end_header_id|>\\n\\nCategory:')[1].split('<|eot_id|>')[0].strip() for d in decode]"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-11-17T18:16:05.380024Z","iopub.status.busy":"2024-11-17T18:16:05.379673Z","iopub.status.idle":"2024-11-17T18:16:05.389148Z","shell.execute_reply":"2024-11-17T18:16:05.388421Z","shell.execute_reply.started":"2024-11-17T18:16:05.379998Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['Positive\\n or Category: Neutral\\n or Category: Neutral\\n or Category: Positive',\n"," 'Negative',\n"," 'Negative\\n or Category: Neutral\\n or Category: Neutral\\n or Category: Positive\\n or Category: Neutral\\nThe best answer',\n"," 'Neutral\\n or Category: Negative\\n or Category: Positive\\n or Category: Negative',\n"," 'Positive\\nor\\nor Category: Negative']"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["predicted_labels[:5]"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-11-17T18:16:05.390391Z","iopub.status.busy":"2024-11-17T18:16:05.390106Z","iopub.status.idle":"2024-11-17T18:16:07.152904Z","shell.execute_reply":"2024-11-17T18:16:07.151732Z","shell.execute_reply.started":"2024-11-17T18:16:05.390367Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.1320\n","Precision: 0.3985\n","Recall: 0.1320\n","F1 Score: 0.1729\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}],"source":["from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","true_labels = df_test['labels'][:500].tolist()  # True labels from the test dataframe\n","\n","# Calculate the metrics: Accuracy, Precision, Recall, F1 Score\n","def calculate_metrics(predictions, true_labels):\n","    accuracy = accuracy_score(true_labels, predictions)\n","    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n","    return accuracy, precision, recall, f1\n","\n","accuracy, precision, recall, f1 = calculate_metrics(predicted_labels, true_labels)\n","\n","# Print the evaluation results\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"datasetId":6105134,"sourceId":9931817,"sourceType":"datasetVersion"}],"dockerImageVersionId":30788,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.15"}},"nbformat":4,"nbformat_minor":4}
